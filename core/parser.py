from .token import Token, TokenType
from .lexer import Lexer
from .ast import BinOP, Num, UnaryOP
from .nodevisitor import NodeVisitor
from .exception import ExceptionHandler
import logging

class Parser(NodeVisitor):
    """
    Parser class to process the tokens generated by the lexer 

    :param lexer: The lexical analyzer used
    :type lexer: Lexer()
    """
    def __init__(self, lexer: Lexer):
        self.logger: logging.Logger = logging.getLogger(__name__)
        self.ExceptionHandler: ExceptionHandler = ExceptionHandler(__name__)
        self.lexer: Lexer = lexer
        self.cur_token: Token = self.lexer.get_next_token()
    
    def eat(self, token_type: TokenType):
        """
        Compares the current token type with the token type passed, and consumes the current token if a match is found.
        Otherwise, an exception is raised
        """
        if self.cur_token.type == token_type:
            self.cur_token = self.lexer.get_next_token()
        else:
            self.logger.error(f"Token 1: {self.cur_token.type}. Token 2: {token_type}")
            self.ExceptionHandler.raise_exception("Tokens do not match")

    def factor(self) -> Num | BinOP:
        """
        Parses a factor statement
        Ruleset: <factor> ::= [("-" | "+")] <factor> | <int> | <LPAREN> <expr> <RPAREN>

        :return: Evaluation result(s)
        :rtype: BinOP() | Num()
        """
        token: Token = self.cur_token
        if token.type == TokenType.PLUS:
            self.eat(TokenType.PLUS)
            node = UnaryOP(token, self.factor())
            return node
        elif token.type == TokenType.MINUS:
            self.eat(TokenType.MINUS)
            node = UnaryOP(token, self.factor())
            return node
        elif token.type == TokenType.INTEGER:
            self.eat(TokenType.INTEGER)
            return Num(token)
        elif token.type == TokenType.LPAREN:
            self.eat(TokenType.LPAREN)
            node = self.expr()
            self.eat(TokenType.RPAREN)
            return node

    def term(self) -> BinOP:
        """
        Parses a term statement
        Rulset: <term> ::= <factor> {("/" | "*") <factor>}

        :return: Evaluation result(s)
        :rtype: BinOP()
        """
        node = self.factor()
        while self.cur_token.type in (TokenType.MUL, TokenType.DIV):
            token = self.cur_token
            if token.type == TokenType.MUL:
                self.eat(TokenType.MUL)
            elif token.type == TokenType.DIV:
                self.eat(TokenType.DIV)
            else:
                pass # Placeholder
            node = BinOP(left=node, op=token, right=self.factor())
        return node


    def expr(self) -> BinOP:
        """
        Parses an expression statement
        Ruleset: <expr> ::= <term> {("-" | "+") <term>}

        :return: Evaluation result(s)
        :rtype: BinOP()
        """
        # Simple expression parsing for x + y
        node = self.term()
        while self.cur_token.type in (TokenType.PLUS, TokenType.MINUS):
            token = self.cur_token
            if token.type == TokenType.PLUS:
                self.eat(TokenType.PLUS)
            elif token.type == TokenType.MINUS:
                self.eat(TokenType.MINUS)
            else:
                pass # Placeholder
            node = BinOP(left=node, op=token, right=self.factor())
        return node

    def parse(self) -> BinOP:
        """
        Calls and returns an expression

        :return: Evaluation result(s)
        :rtype: BinOP()
        """
        return self.expr()